{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "\n",
    "with open(filename, 'rb') as pickle_file:\n",
    "    content = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.77990929e-03, 1.70734688e-02, 2.60327190e-02, 8.34729518e-03,\n",
       "       2.12080591e-02, 1.92033818e-03, 1.01796582e-01, 8.54020568e-05,\n",
       "       6.41102781e-05, 3.13296529e-01, 1.39790294e-03, 2.55233988e-01,\n",
       "       2.49763697e-01])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up\n",
    "pip install azureml-sdk\n",
    "pip install azureml-core\n",
    "\n",
    "#### Reference:\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-existing-model\n",
    "\n",
    "#### Where to deploy: \n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.get(name='AzureMLWorkspaceName',\n",
    "               subscription_id='XXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX',\n",
    "               resource_group='ResourceGroupName'\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register existing ML model (in pickle format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model finalized_model\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path=\"finalized_model.pkl\",\n",
    "                          model_name=\"finalized_model\",\n",
    "                          description=\"Test register model from external\",\n",
    "                          workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will put in score_pbi2.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.standard_py_parameter_type import StandardPythonParameterType\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "# Called when the deployed service starts\n",
    "def init():\n",
    "    global model\n",
    "\n",
    "    # Get the path where the deployed model can be found.\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'))\n",
    "    # load models\n",
    "    with open(model_path + '/finalized_model.pkl', 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "\n",
    "\n",
    "\n",
    "input_sample = pd.DataFrame(data=[{\n",
    "    \"alcohol\": 13.58,\n",
    "    \"malic_acid\": 2.58,\n",
    "    \"ash\": 2.69,\n",
    "    \"alcalinity_of_ash\": 24.5,\n",
    "    \"magnesium\": 105,\n",
    "    \"total_phenols\": 1.55,\n",
    "    \"flavanoids\": 0.84,\n",
    "    \"nonflavanoid_phenols\": 0.39,\n",
    "    \"proanthocyanins\": 1.54,\n",
    "    \"color_intensity\": 8.66,\n",
    "    \"hue\": 0.74 ,\n",
    "    \"od280/od315_of_diluted_wines\":1.8,\n",
    "    \"proline\":750\n",
    "\n",
    "}])\n",
    "\n",
    "# This is an integer type sample. Use the data type that reflects the expected result.\n",
    "output_sample = np.array([0])\n",
    "\n",
    "# To indicate that we support a variable length of data input,\n",
    "# set enforce_shape=False\n",
    "@input_schema('data', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        print(\"input_data....\")\n",
    "        print(data.columns)\n",
    "        print(type(data))\n",
    "        result = model.predict(data)\n",
    "        print(\"result.....\")\n",
    "        print(result)\n",
    "    # You can return any data type, as long as it is JSON serializable.\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inference_schema\n",
      "  Downloading inference_schema-1.1.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\wipadac\\anaconda3\\lib\\site-packages (from inference_schema) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\wipadac\\anaconda3\\lib\\site-packages (from inference_schema) (2.8.1)\n",
      "Collecting wrapt==1.11.1\n",
      "  Downloading wrapt-1.11.1.tar.gz (27 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\wipadac\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->inference_schema) (1.15.0)\n",
      "Building wheels for collected packages: wrapt\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.11.1-py3-none-any.whl size=19547 sha256=dc65eb1953dc7235c75f601e8539d88840221f5bbec55ff8efd3217d627ee180\n",
      "  Stored in directory: c:\\users\\wipadac\\appdata\\local\\pip\\cache\\wheels\\90\\d4\\83\\58efda72eb47567053254faec24fe048dced315a0c3f11e8f8\n",
      "Successfully built wrapt\n",
      "Installing collected packages: wrapt, inference-schema\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed inference-schema-1.1.0 wrapt-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install inference_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create the environment\n",
    "myenv = Environment(name=\"pbiendpoint\")\n",
    "conda_dep = CondaDependencies()\n",
    "\n",
    "# Define the packages needed by the model and scripts\n",
    "#conda_dep.add_conda_package(\"tensorflow\")\n",
    "conda_dep.add_conda_package(\"numpy\")\n",
    "conda_dep.add_conda_package(\"scikit-learn\")\n",
    "conda_dep.add_conda_package(\"pandas\")\n",
    "# You must list azureml-defaults as a pip dependency\n",
    "conda_dep.add_pip_package(\"azureml-defaults\")\n",
    "#conda_dep.add_pip_package(\"keras\")\n",
    "#conda_dep.add_pip_package(\"gensim\")\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "\n",
    "for pip_package in [\"inference_schema\"]:\n",
    "    myenv.python.conda_dependencies.add_pip_package(pip_package)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script=\"score_pbi2.py\",\n",
    "                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model finalized_model:1 to C:\\Users\\wipadac\\AppData\\Local\\Temp\\azureml_v76bm24e\\finalized_model\\1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 7f82caa54ce5444dbca309d665b6325b.azurecr.io\n",
      "Logging into Docker registry 7f82caa54ce5444dbca309d665b6325b.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 7f82caa54ce5444dbca309d665b6325b.azurecr.io/azureml/azureml_f5c963dc6f1e8736d24918005d374e59\n",
      " ---> 4cbd8330689f\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 62a8e0d1aede\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6IjQ5MTRmMjYyLWJkYTgtNDZjYy1hOWRiLWM5Y2JkNjk0YjExNyIsInJlc291cmNlR3JvdXBOYW1lIjoiZGF0YWJyaWNrIiwiYWNjb3VudE5hbWUiOiJmb3JlZGVwbG95bW9kZWwiLCJ3b3Jrc3BhY2VJZCI6IjdmODJjYWE1LTRjZTUtNDQ0ZC1iY2EzLTA5ZDY2NWI2MzI1YiJ9LCJtb2RlbHMiOnt9LCJtb2RlbHNJbmZvIjp7fX0= | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 42e5357a1b8a\n",
      " ---> cbc8767e4475\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpi_h73kz8.py' /var/azureml-app/main.py\n",
      " ---> Running in faef27cf54de\n",
      " ---> 8b3c94d37fb7\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in 7631b7a1e235\n",
      " ---> 60a670cc253b\n",
      "Successfully built 60a670cc253b\n",
      "Successfully tagged pbiendpoint2:latest\n",
      "Container (name:objective_kepler, id:f58ee7392d4e58be258bde8522b849381172883c4059b5756d2269d7b54f3695) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:be44171e652af8b27fa17ba932591b84a0091a5bf91ef8e557bdf063691097ea successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:32771\n",
      "running\n",
      "scoring URI: http://localhost:32771/score\n"
     ]
    }
   ],
   "source": [
    "# Test on local deployment \n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration()\n",
    "model = Model(ws, name='finalized_model')\n",
    "service = Model.deploy(ws, 'pbiendpoint2', [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)\n",
    "print(\"scoring URI: \" + service.scoring_uri)\n",
    "\n",
    "# If pass then deploy to ML Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running.......................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "scoring URI: http://9547dae0-e3cc-4638-9d4e-e37fe26b3826.southeastasia.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "service = Model.deploy(ws, \"pbiendpoint\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(\"scoring URI: \" + service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-73d0935d5417>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m input_payload = json.dumps({\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;34m'data'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m  \u001b[1;31m# If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m })\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Test Calling Service \n",
    "X_df = pd.read_csv('test_scoring_nopredict.csv')\n",
    "\n",
    "import json\n",
    "\n",
    "input_payload = json.dumps({\n",
    "    'data': X_df[0:2].values.tolist()\n",
    " # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}